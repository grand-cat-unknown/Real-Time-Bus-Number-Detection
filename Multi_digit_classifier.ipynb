{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda env:tensorflow]","language":"python","name":"conda-env-tensorflow-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"Multi_digit_classifier.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"if9PDFhcZboY","colab_type":"text"},"source":["# Multi digit classification\n","\n","### Recognizing digit sequences from the original SVHN dataset using TensorFlow\n","\n","---\n","\n","The following notebook details the implementation of a Convolutional Neural Network to recognize sequences of digits in natural images taken from the SVHN dataset.\n","\n","It is an implementation of this [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf).\n","I have broken the notebook into two parts as TensorFlow programs are usually structured into a **construction phase**, that assembles a graph, and an **execution phase** that uses a session to execute ops in the graph.\n","\n","Let's start by importing some libraries and load our dataset.\n","\n","<hr/>"]},{"cell_type":"markdown","metadata":{"id":"xeMDrq2cRcSI","colab_type":"text"},"source":["NOTE 1:</br>\n","\n","The model's input is in 'h5' format. The h5 files are the output of the '**Digit_Detection/TF_Implementation/SVHN-preprocessor.ipynb**'. \n","But you **don't** **need** to run that before this. As the h5 files are provided with the drive folder.\n","This notebook's saved results are the ouput after 56,000 iterations. \n","\n","<br/>\n","<hr/>"]},{"cell_type":"markdown","metadata":{"id":"QjlY8JW8YtLg","colab_type":"text"},"source":["NOTE 2:\n","\n","Even though this model achieves 90.4% accuracy on the test set. I have used ssd_mobilenetv1 for actual bus number detection.\n","This notebook is only for multi-digit classification not for bounding box detection. \n","\n","<hr/>"]},{"cell_type":"code","metadata":{"id":"jPesGCWtZbog","colab_type":"code","outputId":"7012445a-ab9a-48a4-cdf6-6779c57491cd","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1577970008696,"user_tz":-330,"elapsed":12821,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","!pip install scipy==1.0.0\n","\n","import h5py\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import seaborn as sns\n","import numpy as np\n","import time\n","import os\n","from datetime import timedelta\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (16.0, 4.0)\n","\n","print(\"Tensorflow version: \" + tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tensorflow version: 1.15.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fsWn3gKyZgbi","colab_type":"code","outputId":"c7cfad0a-2ea5-4f9e-f13a-c5722ccdc60d","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1577970006658,"user_tz":-330,"elapsed":10802,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%tensorflow_version 1.x\n","dir_path = '/content/drive/My Drive/trail_ready/'\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scipy==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.0.0) (1.17.4)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xFnOgfaRZbot","colab_type":"text"},"source":["## Loading the data\n","\n","Let's load the greyscale images created in our previous notebook"]},{"cell_type":"code","metadata":{"id":"eEVkFrcIZbow","colab_type":"code","outputId":"95513681-6069-4984-baae-1fc1ac9c3c73","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1577970010776,"user_tz":-330,"elapsed":14869,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["import os \n","\n","##CHANGE TO ROOT_DIR\n","\n","model_name = dir_path+'Digit_Detection/TF_Implementation/svhn_multi_v5'\n","h5f = h5py.File(dir_path+'Digit_Detection/TF_Implementation/SVHN_multi_grey.h5','r')\n","\n","# Extract the datasets\n","X_train = h5f['train_dataset'][:]\n","y_train = h5f['train_labels'][:]\n","X_val = h5f['valid_dataset'][:]\n","y_val = h5f['valid_labels'][:]\n","X_test = h5f['test_dataset'][:]\n","y_test = h5f['test_labels'][:]\n","\n","# Close the file\n","h5f.close()\n","\n","print('Training set', X_train.shape, y_train.shape)\n","print('Validation set', X_val.shape, y_val.shape)\n","print('Test set', X_test.shape, y_test.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Training set (230754, 32, 32, 1) (230754, 5)\n","Validation set (5000, 32, 32, 1) (5000, 5)\n","Test set (13068, 32, 32, 1) (13068, 5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"INH_d-3FZbo9","colab_type":"text"},"source":["Keep the data dimensions as they will be reused multiple times in the following code"]},{"cell_type":"code","metadata":{"id":"2X_52iyzZbpA","colab_type":"code","colab":{}},"source":["# Get the data dimensions\n","_, img_height, img_width, num_channels = X_train.shape\n","\n","# ... and label information\n","num_digits, num_labels = y_train.shape[1], len(np.unique(y_train))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jBBquzTnZbpG","colab_type":"text"},"source":["When we are done tuning the hyperparameters we want to use all the data for training to boost our testset score."]},{"cell_type":"code","metadata":{"id":"wyUcCUcGZbpI","colab_type":"code","outputId":"f55f9a64-1d01-4af0-8026-17fda1acb003","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1577970010780,"user_tz":-330,"elapsed":14838,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["X_train = np.concatenate([X_train, X_val])\n","y_train = np.concatenate([y_train, y_val])\n","\n","print('Training set', X_train.shape, y_train.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Training set (235754, 32, 32, 1) (235754, 5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"S3eXLbVdZbpL","colab_type":"text"},"source":["Let's shuffle the training set using ``sklearn.utils.shuffle``"]},{"cell_type":"code","metadata":{"id":"8y21aHPaZbpM","colab_type":"code","colab":{}},"source":["from sklearn.utils import shuffle\n","\n","# Randomly shuffle the training data\n","X_train, y_train = shuffle(X_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R944zHh-ZbpQ","colab_type":"text"},"source":["### Data Preprocessing\n","\n","Mean subtraction is the most common form of preprocessing. It involves subtracting the mean across every individual feature in the data, and has the geometric interpretation of centering the cloud of data around the origin along every dimension. [``Goodfellow et al.``](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf) (96.03%) and [``Ba et al.``](https://arxiv.org/pdf/1412.7755.pdf) (96.1%) both preprocess the images by subtracting the mean of every image."]},{"cell_type":"code","metadata":{"id":"XhSHfWqoZbpR","colab_type":"code","colab":{}},"source":["def subtract_mean(a):\n","    \"\"\" Helper function for subtracting the mean of every image\n","    \"\"\"\n","    for i in range(a.shape[0]):\n","        a[i] = np.subtract(a[i],a[i].mean(),casting='unsafe')\n","    return a\n","\n","\n","# Subtract the mean from every image\n","X_train = subtract_mean(X_train)\n","X_test = subtract_mean(X_test)\n","X_val = subtract_mean(X_val)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WBBdtrJNZbpU","colab_type":"text"},"source":["## Helper functions\n","\n","Let's implement some helper functions to make our notebook easier to read and reduce code duplication.\n","\n","### Helper function for plotting images\n","\n","Here is a simple helper function that will help us plot ``nrows`` * ``ncols``Â images and their true and predicted labels."]},{"cell_type":"code","metadata":{"id":"5gbBdYcsZbpV","colab_type":"code","colab":{}},"source":["def plot_images(images, nrows, ncols, cls_true, cls_pred=None):\n","    \n","    # Initialize figure\n","    fig, axes = plt.subplots(nrows, ncols, figsize=(16, 2*nrows))\n","    \n","    # Randomly select nrows * ncols images\n","    rs = np.random.choice(images.shape[0], nrows*ncols)\n","    \n","    # For every axes object in the grid\n","    for i, ax in zip(rs, axes.flat): \n","        \n","        # Pretty string with actual number\n","        true_number = ''.join(str(x) for x in cls_true[i] if x != 10)\n","        \n","        if cls_pred is None:\n","            title = \"True: {0}\".format(true_number)\n","        else:\n","            # Pretty string with predicted number\n","            pred_number = ''.join(str(x) for x in cls_pred[i] if x != 10)\n","            title = \"True: {0}, Pred: {1}\".format(true_number, pred_number) \n","            \n","        ax.imshow(images[i,:,:,:])\n","        ax.set_title(title)   \n","        ax.set_xticks([]); ax.set_yticks([])\n","        \n","        \n","# Plot some images from the training set\n","# plot_images(X_train, 2, 8, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SSnL59n9ZbpZ","colab_type":"text"},"source":["### Helper functions for creating new variables\n","\n","Functions for creating new [``TensorFlow Variables``](https://www.tensorflow.org/how_tos/variables/) in the given shape and initializing them using using the initialization scheme porposed by [``Gloret et al.``](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)"]},{"cell_type":"code","metadata":{"id":"8HWtwqzKZbpa","colab_type":"code","colab":{}},"source":["def init_conv_weights(shape, name):\n","    return tf.get_variable(name, shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n","\n","def init_fc_weights(shape, name):\n","    return tf.get_variable(name, shape, initializer=tf.contrib.layers.xavier_initializer())\n","\n","def init_biases(shape):\n","    return tf.Variable(tf.constant(0.0, shape=shape))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_6K5MRUZbpe","colab_type":"text"},"source":["### Helper function for stacking CONV-RELU layers followed by an optional POOL layer\n","\n","This function creates a new convolutional layer in the computational graph for TensorFlow. The most common form of a ConvNet architecture stacks a few CONV-RELU layers, follows them with POOL layers, and repeats this pattern until the image has been merged spatially to a small size. At some point it is common to transition to fully connected layers.\n","\n","In other words, the most common ConvNet archiecture follows the pattern:\n","\n","```INPUT > [[CONV -> RELU]*N -> POOL?]M -> [FC -> RELU]*K -> FC```\n","\n","The following helper function simplifies the creation of this pattern"]},{"cell_type":"code","metadata":{"id":"CYKWf6NQZbpf","colab_type":"code","colab":{}},"source":["def conv_layer(input_tensor,    # The input or previous layer\n","                filter_size,    # Width and height of each filter\n","                in_channels,    # Number of channels in previous layer\n","                num_filters,    # Number of filters\n","                layer_name,     # Layer name\n","                pooling):       # Use 2x2 max-pooling?\n","    \n","    # Add layer name scopes for better graph visualization\n","    with tf.name_scope(layer_name):\n","    \n","        # Shape of the filter-weights for the convolution\n","        shape = [filter_size, filter_size, in_channels, num_filters]\n","\n","        # Create weights and biases\n","        weights = init_conv_weights(shape, layer_name + '/weights')\n","        biases = init_biases([num_filters])\n","        \n","        # Add histogram summaries for weights\n","        tf.summary.histogram(layer_name + '/weights', weights)\n","        \n","        # Create the TensorFlow operation for convolution, with S=1 and zero padding\n","        activations = tf.nn.conv2d(input_tensor, weights, [1, 1, 1, 1], 'SAME') + biases\n","\n","        # Rectified Linear Unit (ReLU)\n","        activations = tf.nn.relu(activations)\n","\n","        # Do we insert a pooling layer?\n","        if pooling:\n","            # Create a pooling layer with F=2, S=1 and zero padding\n","            activations = tf.nn.max_pool(activations, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n","\n","        # Return the resulting layer\n","        return activations"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xnqId3ZXZbpi","colab_type":"text"},"source":["### Helper function for reshaping the CONV layers to FC layers\n","\n","A convolutional layer produces an output tensor with 4 dimensions. We will add fully-connected layers after the convolution layers, so we need to reduce the 4-dim tensor to 2-dim which can be used as input to the fully-connected layer. E.g., if the input layer has the shape (?, 8, 8, 32) the flattened layer will have the shape (?, 8 x 8 x 32) or (?, 2048)."]},{"cell_type":"code","metadata":{"id":"HGo9wgocZbpk","colab_type":"code","colab":{}},"source":["def flatten_tensor(input_tensor):\n","    \"\"\" Helper function for transforming a 4D tensor to 2D\n","    \"\"\"\n","    # Get the shape of the input_tensor.\n","    input_tensor_shape = input_tensor.get_shape()\n","\n","    # Calculate the volume of the input tensor\n","    num_activations = input_tensor_shape[1:4].num_elements()\n","    \n","    # Reshape the input_tensor to 2D: (?, num_activations)\n","    input_tensor_flat = tf.reshape(input_tensor, [-1, num_activations])\n","\n","    # Return the flattened input_tensor and the number of activations\n","    return input_tensor_flat, num_activations"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"svToVWa6Zbpn","colab_type":"text"},"source":["### Helper function for stacking FC-RELU layers\n","\n","This function creates a new fully-connected layer in the computational graph for TensorFlow. Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can hence be computed with a matrix multiplication followed by a bias offset.\n","\n","As mentioned in previous section most ConvNet architectures follows the following pattern:\n","\n","```INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC```\n","\n","The following helper function will simplify the process of stacking FC and RELU layers"]},{"cell_type":"code","metadata":{"id":"hbfjr6V7Zbpo","colab_type":"code","colab":{}},"source":["def fc_layer(input_tensor,  # The previous layer,         \n","             input_dim,     # Num. inputs from prev. layer\n","             output_dim,    # Num. outputs\n","             layer_name,    # The layer name\n","             relu=False):         # Use ReLU?\n","\n","    # Add layer name scopes for better graph visualization\n","    with tf.name_scope(layer_name):\n","    \n","        # Create new weights and biases.\n","        weights = init_fc_weights([input_dim, output_dim], layer_name + '/weights')\n","        biases = init_biases([output_dim])\n","        \n","        # Add histogram summaries for weights\n","        tf.summary.histogram(layer_name + '/weights', weights)\n","\n","        # Calculate the layer activation\n","        activations = tf.matmul(input_tensor, weights) + biases\n","\n","        # Use ReLU?\n","        if relu:\n","            activations = tf.nn.relu(activations)\n","\n","        return activations"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F5GqT22MZbps","colab_type":"text"},"source":["## Tensorflow Model\n","\n","The configuration of the Convolutional Neural Network and data dimensions are defined here for convenience, so you can easily find and change these numbers and re-run the Notebook."]},{"cell_type":"code","metadata":{"id":"37r2YMUhZbpt","colab_type":"code","colab":{}},"source":["# Block 1\n","filter_size1 = filter_size2 = 5          \n","num_filters1 = num_filters2 = 32        \n","\n","# Block 2\n","filter_size3 = filter_size4 = 5          \n","num_filters3 = num_filters4 = 64\n","\n","# Block 3\n","filter_size5 = filter_size6 = filter_size7 = 5          \n","num_filters5 = num_filters6 = num_filters7 = 128  \n","\n","# Fully-connected layers\n","fc1_size = fc2_size = 256"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7heWsIWZbpw","colab_type":"text"},"source":["### Placeholder Variables\n","\n","Placeholder variables serve as the input to the graph that we may change each time we execute the graph"]},{"cell_type":"code","metadata":{"id":"bjYaHZcgZbpx","colab_type":"code","colab":{}},"source":["with tf.name_scope(\"input\"):\n","    \n","    # Placeholders for feeding input images\n","    x = tf.placeholder(tf.float32, shape=(None, img_height, img_width, num_channels), name='x')\n","    y_ = tf.placeholder(tf.int64, shape=[None, num_digits], name='y_')\n","\n","with tf.name_scope(\"dropout\"):\n","    \n","    # Dropout rate applied to the input layer\n","    p_keep_1 = tf.placeholder(tf.float32)\n","    tf.summary.scalar('input_keep_probability', p_keep_1)\n","\n","    # Dropout rate applied after the pooling layers\n","    p_keep_2 = tf.placeholder(tf.float32)\n","    tf.summary.scalar('conv_keep_probability', p_keep_2)\n","\n","    # Dropout rate using between the fully-connected layers\n","    p_keep_3 = tf.placeholder(tf.float32)\n","    tf.summary.scalar('fc_keep_probability', p_keep_3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rxnfr1gRZbp0","colab_type":"text"},"source":["### Model\n","\n","We implement the following ConvNet architecture\n","\n","`INPUT -> [[CONV -> RELU]*2 -> POOL]*2 -> [[CONV -> RELU]*3 -> POOL] -> [FC -> RELU]*2 -> OUTPUT`"]},{"cell_type":"code","metadata":{"id":"X5DOeXSEZbp2","colab_type":"code","outputId":"a3561893-2f2b-4062-f245-21525d227371","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1577970016790,"user_tz":-330,"elapsed":20644,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["# tf.reset_default_graph() \n","# Apply dropout to the input layer\n","drop_input = tf.nn.dropout(x, p_keep_1) \n","\n","# Block 1\n","conv_1 = conv_layer(drop_input, filter_size1, num_channels, num_filters1, \"conv_1\", pooling=False)\n","conv_2 = conv_layer(conv_1, filter_size2, num_filters1, num_filters2, \"conv_2\", pooling=True)\n","drop_block1 = tf.nn.dropout(conv_2, p_keep_2) # Dropout\n","\n","# Block 2\n","conv_3 = conv_layer(conv_2, filter_size3, num_filters2, num_filters3, \"conv_3\", pooling=False)\n","conv_4 = conv_layer(conv_3, filter_size4, num_filters3, num_filters4, \"conv_4\", pooling=True)\n","drop_block2 = tf.nn.dropout(conv_4, p_keep_2) # Dropout\n","\n","# Block 3\n","conv_5 = conv_layer(drop_block2, filter_size5, num_filters4, num_filters5, \"conv_5\", pooling=False)\n","conv_6 = conv_layer(conv_5, filter_size6, num_filters5, num_filters6, \"conv_6\", pooling=False)\n","conv_7 = conv_layer(conv_6, filter_size7, num_filters6, num_filters7, \"conv_7\", pooling=True)\n","flat_tensor, num_activations = flatten_tensor(tf.nn.dropout(conv_7, p_keep_3)) # Dropout\n","\n","# Fully-connected 1\n","fc_1 = fc_layer(flat_tensor, num_activations, fc1_size, 'fc_1', relu=True)\n","drop_fc2 = tf.nn.dropout(fc_1, p_keep_3) # Dropout\n","\n","# Fully-connected 2\n","fc_2 = fc_layer(drop_fc2, fc1_size, fc2_size, 'fc_2', relu=True)\n","\n","# Paralell softmax layers\n","logits_1 = fc_layer(fc_2, fc2_size, num_labels, 'softmax1')\n","logits_2 = fc_layer(fc_2, fc2_size, num_labels, 'softmax2')\n","logits_3 = fc_layer(fc_2, fc2_size, num_labels, 'softmax3')\n","logits_4 = fc_layer(fc_2, fc2_size, num_labels, 'softmax4')\n","logits_5 = fc_layer(fc_2, fc2_size, num_labels, 'softmax5')\n","\n","y_pred = tf.stack([logits_1, logits_2, logits_3, logits_4, logits_5])\n","\n","# The class-number is the index of the largest element\n","y_pred_cls = tf.transpose(tf.argmax(y_pred, dimension=2))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-15-a4ef1768eccc>:1: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-15-a4ef1768eccc>:36: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use the `axis` argument instead\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f9Wg95iTZbp5","colab_type":"text"},"source":["### Loss Function\n","\n","We calculate the loss by taking the average loss of every individual example for each of our 5 digits and adding them together. Using ``tf.nn.sparse_softmax_cross_entropy_with_logits`` allows us to skip using OneHotEncoding on our label values."]},{"cell_type":"code","metadata":{"id":"dWuYva_TZbp6","colab_type":"code","colab":{}},"source":["with tf.name_scope('loss'):\n","    \n","    # Calculate the loss for each individual digit in the sequence\n","    loss1 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits= logits_1,labels= y_[:, 0]))\n","    loss2 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_2, labels=y_[:, 1]))\n","    loss3 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_3, labels=y_[:, 2]))\n","    loss4 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_4, labels=y_[:, 3]))\n","    loss5 = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_5, labels=y_[:, 4]))\n","\n","    # Calculate the total loss for all predictions\n","    loss = loss1 + loss2 + loss3 + loss4 + loss5\n","    tf.summary.scalar('loss', loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUk69HAVZbp9","colab_type":"text"},"source":["### Optimization Method\n","\n","In training deep networks, it is usually helpful to anneal the learning rate over time. Typical values might be reducing the learning rate by a half every 5 epochs. Using a batch size of 64 gives us 3600 steps per epoch or 18,000 steps for 5 ephocs. A typical sampling of the starting learning rate could looks something like this:"]},{"cell_type":"code","metadata":{"id":"EcYFl74yZbp-","colab_type":"code","outputId":"34561273-a5b2-4c7d-86a2-d369be921419","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1577970016796,"user_tz":-330,"elapsed":20584,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["10 ** np.random.uniform(-6, 1)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.03840560821078631"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"_FoK1DuvZbqF","colab_type":"text"},"source":["Now that we have a cost measure that must be minimized, we can then create an optimizer. In this case it is the RMS which is an advanced form of Gradient Descent. Adam is currently the recommended optimizer but RMSProp and SGD + Nesterov Momentum are also good alternatives. For more information on Per-parameter adaptive learning rate methods see the [``CS231n notes``](http://cs231n.github.io/neural-networks-3/#ada). "]},{"cell_type":"code","metadata":{"id":"0ja9vHopZbqH","colab_type":"code","outputId":"21fa7a55-63c0-4ce8-ed73-840b3a74b771","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1577970018219,"user_tz":-330,"elapsed":21982,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["with tf.name_scope('optimizer'):\n","    \n","    # Global step is required to compute the decayed learning rate\n","    global_step = tf.Variable(0, trainable=False)\n","\n","    # Apply exponential decay to the learning rate\n","    learning_rate = tf.train.exponential_decay(1e-3, global_step, 7500, 0.5, staircase=True)\n","    tf.summary.scalar('learning_rate', learning_rate)\n","\n","    # Construct a new Adam optimizer\n","    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, global_step=global_step)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"btuGt4CgZbqN","colab_type":"text"},"source":["### Evaluation Metric\n","\n","To evaluate the performance of our Convolutional Network we calculate the average accuracy across all samples"]},{"cell_type":"code","metadata":{"id":"w4YlbN45ZbqO","colab_type":"code","colab":{}},"source":["with tf.name_scope(\"accuracy\"):\n","    \n","    # Predicted class equals the true class of each image?\n","    correct_prediction = tf.reduce_min(tf.cast(tf.equal(y_pred_cls, y_), tf.float32), 1)\n","\n","    # Cast predictions to float and calculate the mean\n","    accuracy = tf.reduce_mean(correct_prediction) * 100.0\n","    \n","    # Add scalar summary for accuracy tensor\n","    tf.summary.scalar('accuracy', accuracy)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xHj3tSUKZbqR","colab_type":"text"},"source":["### TensorFlow Run\n","\n","Once the TensorFlow graph has been created, we have to create a TensorFlow session which is used to execute the graph."]},{"cell_type":"code","metadata":{"id":"3RG0rsBlZbqS","colab_type":"code","colab":{}},"source":["# Launch the graph in a session\n","session = tf.Session()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ki1yWryhbOm3","colab_type":"text"},"source":["Load checkpoint"]},{"cell_type":"code","metadata":{"id":"344Yx9kLtj5i","colab_type":"code","outputId":"36147df9-e4ea-4003-c530-02abf6e1a759","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1577970018225,"user_tz":-330,"elapsed":21852,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["saver = tf.train.Saver()\n","\n","##Try to load the saved checkpoint else just start fresh\n","try:\n","  saver.restore(session, save_path=dir_path+'Digit_Detection/TF_Implementation/'+'svhn_multi_v5'+'-'+str(56200))\n","except:\n","  session.run(tf.global_variables_initializer())\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/drive/My Drive/trail_ready/Digit_Detection/TF_Implementation/svhn_multi_v5-56200\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AOgYXwq8Zbqe","colab_type":"text"},"source":["## Optimization\n","\n","Let's optimize or train our network. The batch size is the number of training examples we compute the gradient over during training while the dropout rates control the amount of dropout (the percentage of random units that is removed) applied in the different layers of the model."]},{"cell_type":"code","metadata":{"id":"jlJ4lg2EZbqf","colab_type":"code","colab":{}},"source":["# If you run out of memory - switch to a smaller batch size\n","batch_size = 128 \n","\n","# Dropout applied to the input layer\n","d1 = 0.9\n","\n","# Dropout applied between the conv layers\n","d2 = 0.75\n","\n","# Dropout applied to the fully-connected layers\n","d3 = 0.5 "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fa2xskMmZbqi","colab_type":"text"},"source":["In each iteration, a new batch of data is selected from the training-set and then TensorFlow executes the optimizer using those training samples. The following helper function simplifies the creation of fetching a new batch of data. Feeding over 10,000 samples as once (the test set) is also sure to cause some memory problems. The second function splits the validation and test set into batches and calculates the accuracy over all of the batches."]},{"cell_type":"code","metadata":{"id":"k59GJPLvZbqj","colab_type":"code","colab":{}},"source":["def feed_dict(step=0):\n","    \"\"\" Make a TensorFlow feed_dict mapping data onto the placeholders\n","    \"\"\"\n","    # Calculate the offset\n","    offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n","    \n","    # Get the batch data\n","    xs, ys = X_train[offset:offset + batch_size], y_train[offset:offset+batch_size]\n","        \n","    return {x: xs, y_: ys, p_keep_1: d1, p_keep_2: d2, p_keep_3: d3}\n","\n","\n","def evaluate_batch(test, batch_size):\n","    \"\"\" Evaluate in batches to avoid out-of-memory issues\n","    \"\"\"\n","    # Store the cumulative accuracy over all batches\n","    cumulative_accuracy = 0.0\n","    \n","    # Get the number of images\n","    n_images = y_test.shape[0] if test else y_val.shape[0]\n","    \n","    # Numer of batches needed to evaluate all images\n","    n_batches = n_images // batch_size + 1\n","    \n","    # Iterate over all the batches\n","    for i in range(n_batches):\n","        \n","        # Calculate the offset\n","        offset = i * batch_size\n","     \n","        if test:\n","            # Get the batch from the test set\n","            xs, ys = X_test[offset:offset+batch_size], y_test[offset:offset+batch_size]\n","        else:\n","            # Get batch from the validation set\n","            xs, ys = X_val[offset:offset+batch_size], y_val[offset:offset+batch_size]\n","            \n","        cumulative_accuracy += session.run(accuracy,\n","                {x: xs, y_: ys, p_keep_1: 1., p_keep_2: 1., p_keep_3: 1.})\n","                                           \n","    # Return the average accuracy over all batches\n","    return cumulative_accuracy / (0.0 + n_batches)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"udtD_vlZZbqm","colab_type":"text"},"source":["In each iteration, a new batch of data is selected from the training-set and then TensorFlow executes the optimizer using those training samples. "]},{"cell_type":"code","metadata":{"id":"uQgFQ7X_Zbqn","colab_type":"code","colab":{}},"source":["def optimize(num_iterations, display_step):\n","    # Start-time used for printing time-usage\n","    start_time = time.time()\n","\n","    for step in range(num_iterations):\n","\n","        # Run the optimizer using this batch of training data.\n","        summary, i, _ = session.run([merged, global_step, optimizer], feed_dict(step))\n","        train_writer.add_summary(summary, i)\n","\n","        # Print the status every display_step iteration and last\n","        if (i % display_step == 0) or (step == num_iterations - 1):\n","            \n","            # Calculate the minibatch accuracy\n","            batch_acc = session.run(accuracy, feed_dict=feed_dict(step))\n","            print(\"Minibatch accuracy at step %d: %.4f\" % (i, batch_acc))\n","            \n","            # Calculate the accuracy on the validation-set\n","            #valid_acc = evaluate_batch(test=False, batch_size=512)\n","            #print(\"Validation accuracy at step %s: %.4f\" % (i, valid_acc))\n","\n","    # Total training time\n","    run_time = time.time() - start_time\n","    print(\"\\nTime usage: \" + str(timedelta(seconds=int(round(run_time)))))\n","    \n","    # Calculate and display the testset accuracy\n","    test_acc = evaluate_batch(test=True, batch_size=512)\n","    print(\"Test accuracy: %.4f\" % test_acc)\n","    \n","    # Save all the variables of the TensorFlow graph\n","    saver.save(session, save_path=dir_path +'Digit_Detection/TF_Implementation/svhn_multi_v5', global_step=global_step)\n","    print('Model saved in file: {}'.format(dir_path)+'checkpoints/')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cz-dk8oCZbqr","colab_type":"text"},"source":["Let's run 5,000 iterations and see how well our model performs. When tuning the hyperparameters of the model it could we smart do to a quick search of 1-5 ephocs (complete forward and backward passes over the dataset)"]},{"cell_type":"markdown","metadata":{"id":"4Ri8UcAcbbiw","colab_type":"text"},"source":["Uncomment this if you want to train"]},{"cell_type":"code","metadata":{"id":"I1FAT07HZbqs","colab_type":"code","outputId":"9d66ec96-1b28-4566-f14a-30ae1e8780ee","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1577970091332,"user_tz":-330,"elapsed":94804,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["# optimize(num_iterations=5000, display_step=1)\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Minibatch accuracy at step 56201: 89.0625\n","Minibatch accuracy at step 56202: 87.5000\n","\n","Time usage: 0:00:08\n","Test accuracy: 90.3857\n","Model saved in file: /content/drive/My Drive/trail_ready/checkpoints/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LrUjolz8Zbq0","colab_type":"text"},"source":["### Testset performance\n","\n","Let's plot some of the mis-classified examples in our testset and a confusion matrix showing how well our model is able to predict the different digits."]},{"cell_type":"code","metadata":{"id":"SlmrpcreZbq1","colab_type":"code","outputId":"560e8f24-5911-4c8c-d339-d71b437a2862","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"ok","timestamp":1577970161837,"user_tz":-330,"elapsed":165295,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["# Feed the test set with dropout disabled\n","feed_dict={\n","    x: X_test,\n","    p_keep_1: 1.,\n","    p_keep_2: 1.,\n","    p_keep_3: 1.\n","}\n","\n","# Generate predictions for the testset\n","test_pred = session.run(y_pred_cls, feed_dict=feed_dict)\n","\n","# Display the predictions\n","test_pred\n"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 5, 10, 10, 10, 10],\n","       [ 1,  6, 10, 10, 10],\n","       [ 6,  1, 10, 10, 10],\n","       ...,\n","       [ 3, 10, 10, 10, 10],\n","       [ 2,  1, 10, 10, 10],\n","       [ 2, 10, 10, 10, 10]])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"7dU0RHtIHUtJ","colab_type":"code","outputId":"fe8cc895-6bd1-4a27-f868-774e33695911","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1577970161838,"user_tz":-330,"elapsed":165263,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["## PRINT ACCURACY\n","\n","from operator import sub\n","same = 0\n","for pred,test  in zip(test_pred,y_test):\n","  differences = list( map(sub, pred, test) )\n","  if sum(differences) == 0:\n","    same = same + 1\n","acc = same /float(len(test_pred))\n","print (acc)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["0.9048821548821548\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y2VjzWH4Zbq4","colab_type":"text"},"source":["#### Individual digit accuracy\n","\n","Let's calculate the classifiers accuracy on each individual digit only counting the non missing values."]},{"cell_type":"code","metadata":{"id":"gWABxBN8Zbq5","colab_type":"code","outputId":"eed35be3-978d-429a-8cc5-adb9dc643b87","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1577970161839,"user_tz":-330,"elapsed":165247,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["from sklearn.metrics import accuracy_score\n","\n","# Find the position of the non missing labels\n","non_zero = np.where(y_test.flatten() != 10)\n","\n","# Calculate the accuracy on the individual didgit level\n","accuracy_score(test_pred.flatten()[non_zero], y_test.flatten()[non_zero])"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9416487400122926"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"Is4qW5ecZbrA","colab_type":"text"},"source":["... and plot the confusion matrix to show the performance for each class"]},{"cell_type":"code","metadata":{"id":"BZv1QjpMZbrA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":517},"outputId":"69db255e-28bd-4632-f68d-718ca23ddef7","executionInfo":{"status":"ok","timestamp":1577970162858,"user_tz":-330,"elapsed":166252,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["from sklearn.metrics import confusion_matrix\n","\n","# Set the figure size\n","plt.figure(figsize=(12, 8))\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(y_test.flatten()[non_zero], test_pred.flatten()[non_zero])\n","\n","# Normalize the confusion matrix\n","cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100.0\n","\n","# Visualize the confusion matrix\n","sns.heatmap(cm, annot=True, cmap='Reds', fmt='.1f', square=True);"],"execution_count":32,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n","  # Remove the CWD from sys.path while we load stuff.\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAh0AAAHSCAYAAABINnkbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng/rsMXK2lAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 864x576 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Wr3jyg4qZbrD","colab_type":"text"},"source":["#### Digit sequence lengths impact on performance\n","\n","Let's see how well our model is able to predict the labels correctly for different sequence lengths"]},{"cell_type":"code","metadata":{"id":"TmgjQkSWZbrF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"7e274a27-a60d-4c62-f879-24498879234b","executionInfo":{"status":"ok","timestamp":1577970162859,"user_tz":-330,"elapsed":166229,"user":{"displayName":"Srikanth G","photoUrl":"","userId":"11541868147925154892"}}},"source":["def calculate_accuracy(a, b):\n","    \"\"\" Calculating the % of similar rows in two numpy arrays \n","    \"\"\"\n","    # Compare two numpy arrays row-wise\n","    correct = np.sum(np.all(a == b, axis=1))\n","    return 100.0 * (correct / (0.0 + a.shape[0]))\n","    \n","    \n","# For every possible sequence length\n","for num_digits in range(1, 6):\n","    \n","    # Find all images with that given sequence length\n","    images = np.where((y_test != 10).sum(1) == num_digits)\n","    \n","    # Calculate the accuracy on those images\n","    acc = calculate_accuracy(test_pred[images], y_test[images])\n","    \n","    print(\"%d digit accuracy %.3f %%\" % (num_digits, acc))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["1 digit accuracy 90.818 %\n","2 digit accuracy 91.587 %\n","3 digit accuracy 85.968 %\n","4 digit accuracy 77.397 %\n","5 digit accuracy 0.000 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K7VPGpjJZwnn","colab_type":"code","colab":{}},"source":["# Credits\n","# This application uses Open Source components.\n","# You can find the source code of their open source projects along with license information below.\n","# I acknowledge and are grateful to these developers for their contributions to open source."],"execution_count":0,"outputs":[]}]}